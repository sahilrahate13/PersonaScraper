{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81a48250-584e-4532-8b0a-a159b63b0d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Installed praw\n",
      "âœ“ Installed google-generativeai\n",
      "âœ“ Installed python-dotenv\n",
      "âœ“ Installed requests\n",
      "âœ“ Installed beautifulsoup4\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    'praw',\n",
    "    'google-generativeai',\n",
    "    'python-dotenv',\n",
    "    'requests',\n",
    "    'beautifulsoup4'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "        print(f\"âœ“ Installed {package}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"âœ— Failed to install {package}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f377536e-5ee3-40c2-a3d3-49a886abe691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "import time\n",
    "\n",
    "\n",
    "def install_packages():\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    packages = [\n",
    "        'praw',\n",
    "        'google-generativeai',\n",
    "        'python-dotenv',\n",
    "        'requests',\n",
    "        'beautifulsoup4'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "            print(f\"âœ“ Installed {package}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"âœ— Failed to install {package}\")\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Citation:\n",
    "    \"\"\"Represents a citation for a persona characteristic\"\"\"\n",
    "    content: str\n",
    "    post_type: str  # 'post' or 'comment'\n",
    "    url: str\n",
    "    created_utc: float\n",
    "    subreddit: str\n",
    "    score: int\n",
    "\n",
    "@dataclass\n",
    "class PersonaCharacteristic:\n",
    "    \"\"\"Represents a characteristic with its citations\"\"\"\n",
    "    value: str\n",
    "    citations: List[Citation]\n",
    "\n",
    "@dataclass\n",
    "class UserPersona:\n",
    "    \"\"\"Complete user persona structure\"\"\"\n",
    "    # Basic Demographics\n",
    "    estimated_age: PersonaCharacteristic\n",
    "    occupation: PersonaCharacteristic\n",
    "    location: PersonaCharacteristic\n",
    "    relationship_status: PersonaCharacteristic\n",
    "    \n",
    "    # Personality Traits\n",
    "    personality_type: PersonaCharacteristic\n",
    "    interests: PersonaCharacteristic\n",
    "    values: PersonaCharacteristic\n",
    "    \n",
    "    # Behavioral Patterns\n",
    "    communication_style: PersonaCharacteristic\n",
    "    online_behavior: PersonaCharacteristic\n",
    "    activity_patterns: PersonaCharacteristic\n",
    "    \n",
    "    # Motivations & Goals\n",
    "    primary_motivations: PersonaCharacteristic\n",
    "    frustrations: PersonaCharacteristic\n",
    "    goals: PersonaCharacteristic\n",
    "    \n",
    "    # Technical Profile\n",
    "    tech_savviness: PersonaCharacteristic\n",
    "    preferred_platforms: PersonaCharacteristic\n",
    "    \n",
    "    # Quote\n",
    "    representative_quote: PersonaCharacteristic\n",
    "    \n",
    "    # Metadata\n",
    "    username: str\n",
    "    analysis_date: str\n",
    "    total_posts: int\n",
    "    total_comments: int\n",
    "    account_age_days: int\n",
    "    karma: int\n",
    "\n",
    "class RedditUserPersonaGenerator:\n",
    "    \"\"\"Main class for generating user personas from Reddit profiles\"\"\"\n",
    "    \n",
    "    def __init__(self, reddit_client_id: str = None, reddit_client_secret: str = None, \n",
    "                 reddit_user_agent: str = None, gemini_api_key: str = None):\n",
    "        \"\"\"\n",
    "        Initialize the persona generator\n",
    "        \n",
    "        Args:\n",
    "            reddit_client_id: Reddit app client ID\n",
    "            reddit_client_secret: Reddit app client secret\n",
    "            reddit_user_agent: User agent string\n",
    "            gemini_api_key: Google Gemini API key\n",
    "        \"\"\"\n",
    "        self.reddit = self._initialize_reddit(reddit_client_id, reddit_client_secret, reddit_user_agent)\n",
    "        self._initialize_gemini(gemini_api_key)\n",
    "        \n",
    "    def _initialize_reddit(self, client_id: str, client_secret: str, user_agent: str) -> praw.Reddit:\n",
    "        \"\"\"Initialize Reddit API client\"\"\"\n",
    "        # Try environment variables first, then parameters\n",
    "        client_id = client_id or os.getenv('REDDIT_CLIENT_ID')\n",
    "        client_secret = client_secret or os.getenv('REDDIT_CLIENT_SECRET')\n",
    "        user_agent = user_agent or os.getenv('REDDIT_USER_AGENT', 'PersonaGenerator/1.0')\n",
    "        \n",
    "        if not client_id or not client_secret:\n",
    "            raise ValueError(\"Reddit credentials not provided. Use setup_credentials() or pass them as parameters.\")\n",
    "        \n",
    "        return praw.Reddit(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            user_agent=user_agent,\n",
    "            timeout=60\n",
    "        )\n",
    "    \n",
    "    def _initialize_gemini(self, api_key: str):\n",
    "        \"\"\"Initialize Gemini API client\"\"\"\n",
    "        api_key = api_key or os.getenv('GEMINI_API_KEY')\n",
    "        \n",
    "        if not api_key:\n",
    "            raise ValueError(\"Gemini API key not provided. Use setup_credentials() or pass it as parameter.\")\n",
    "        \n",
    "        genai.configure(api_key=api_key)\n",
    "        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "    \n",
    "    def extract_username_from_url(self, url: str) -> str:\n",
    "        \"\"\"Extract username from Reddit profile URL\"\"\"\n",
    "        patterns = [\n",
    "            r'reddit\\.com/u/([^/]+)',\n",
    "            r'reddit\\.com/user/([^/]+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, url)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "        \n",
    "        raise ValueError(f\"Could not extract username from URL: {url}\")\n",
    "    \n",
    "    def scrape_user_data(self, username: str, limit: int = 100) -> Dict:\n",
    "        \"\"\"Scrape user's posts and comments\"\"\"\n",
    "        try:\n",
    "            user = self.reddit.redditor(username)\n",
    "            \n",
    "            # Get user info\n",
    "            user_info = {\n",
    "                'username': username,\n",
    "                'created_utc': user.created_utc,\n",
    "                'comment_karma': user.comment_karma,\n",
    "                'link_karma': user.link_karma,\n",
    "                'total_karma': user.comment_karma + user.link_karma,\n",
    "                'account_age_days': (datetime.now().timestamp() - user.created_utc) / 86400,\n",
    "                'posts': [],\n",
    "                'comments': []\n",
    "            }\n",
    "            \n",
    "            # Scrape posts\n",
    "            print(f\"ğŸ” Scraping posts for u/{username}...\")\n",
    "            for submission in user.submissions.new(limit=limit):\n",
    "                post_data = {\n",
    "                    'title': submission.title,\n",
    "                    'content': submission.selftext,\n",
    "                    'url': f\"https://reddit.com{submission.permalink}\",\n",
    "                    'subreddit': submission.subreddit.display_name,\n",
    "                    'score': submission.score,\n",
    "                    'created_utc': submission.created_utc,\n",
    "                    'upvote_ratio': submission.upvote_ratio,\n",
    "                    'num_comments': submission.num_comments\n",
    "                }\n",
    "                user_info['posts'].append(post_data)\n",
    "            \n",
    "            # Scrape comments\n",
    "            print(f\"ğŸ’¬ Scraping comments for u/{username}...\")\n",
    "            for comment in user.comments.new(limit=limit):\n",
    "                comment_data = {\n",
    "                    'content': comment.body,\n",
    "                    'url': f\"https://reddit.com{comment.permalink}\",\n",
    "                    'subreddit': comment.subreddit.display_name,\n",
    "                    'score': comment.score,\n",
    "                    'created_utc': comment.created_utc,\n",
    "                    'parent_id': comment.parent_id\n",
    "                }\n",
    "                user_info['comments'].append(comment_data)\n",
    "            \n",
    "            print(f\"âœ“ Found {len(user_info['posts'])} posts and {len(user_info['comments'])} comments\")\n",
    "            return user_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error scraping user data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_with_gemini(self, user_data: Dict) -> Dict:\n",
    "        \"\"\"Use Gemini AI to analyze user data and extract persona characteristics\"\"\"\n",
    "        \n",
    "        # Prepare content for analysis\n",
    "        posts_text = \"\\n\".join([f\"POST: {post['title']} - {post['content']}\" \n",
    "                               for post in user_data['posts'] if post['content']])\n",
    "        comments_text = \"\\n\".join([f\"COMMENT: {comment['content']}\" \n",
    "                                  for comment in user_data['comments']])\n",
    "        \n",
    "        # Prepare subreddit activity\n",
    "        subreddit_activity = {}\n",
    "        for post in user_data['posts']:\n",
    "            subreddit_activity[post['subreddit']] = subreddit_activity.get(post['subreddit'], 0) + 1\n",
    "        for comment in user_data['comments']:\n",
    "            subreddit_activity[comment['subreddit']] = subreddit_activity.get(comment['subreddit'], 0) + 1\n",
    "        \n",
    "        top_subreddits = sorted(subreddit_activity.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Analyze this Reddit user's profile and create a detailed user persona. Based on their posts and comments, extract the following characteristics:\n",
    "\n",
    "        USER DATA:\n",
    "        Username: {user_data['username']}\n",
    "        Account Age: {user_data['account_age_days']:.0f} days\n",
    "        Total Karma: {user_data['total_karma']}\n",
    "        Posts: {len(user_data['posts'])}\n",
    "        Comments: {len(user_data['comments'])}\n",
    "        Top Subreddits: {top_subreddits}\n",
    "\n",
    "        POSTS:\n",
    "        {posts_text[:4000]}\n",
    "\n",
    "        COMMENTS:\n",
    "        {comments_text[:4000]}\n",
    "\n",
    "        Please analyze and provide a JSON response with the following structure. For each characteristic, provide the inferred value and cite specific posts/comments that support your inference. Use actual quotes from the user's content:\n",
    "\n",
    "        {{\n",
    "            \"estimated_age\": {{\n",
    "                \"value\": \"Age range or specific age based on content\",\n",
    "                \"reasoning\": \"Explanation of how you determined this\",\n",
    "                \"evidence\": [\"Direct quote from post/comment that supports this inference\"]\n",
    "            }},\n",
    "            \"occupation\": {{\n",
    "                \"value\": \"Job title or field or 'Unknown' if not clear\",\n",
    "                \"reasoning\": \"Explanation based on content analysis\",\n",
    "                \"evidence\": [\"Supporting quotes from posts/comments\"]\n",
    "            }},\n",
    "            \"location\": {{\n",
    "                \"value\": \"City, Country or region or 'Unknown' if not mentioned\",\n",
    "                \"reasoning\": \"Explanation\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"relationship_status\": {{\n",
    "                \"value\": \"Single/Married/In a relationship/Unknown\",\n",
    "                \"reasoning\": \"Explanation\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"personality_type\": {{\n",
    "                \"value\": \"Personality traits and type description\",\n",
    "                \"reasoning\": \"Explanation based on communication patterns\",\n",
    "                \"evidence\": [\"Supporting quotes showing personality\"]\n",
    "            }},\n",
    "            \"interests\": {{\n",
    "                \"value\": \"List of main interests and hobbies\",\n",
    "                \"reasoning\": \"Based on subreddit activity and content\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"values\": {{\n",
    "                \"value\": \"Core values and beliefs\",\n",
    "                \"reasoning\": \"Explanation\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"communication_style\": {{\n",
    "                \"value\": \"How they communicate online\",\n",
    "                \"reasoning\": \"Analysis of their writing style\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"online_behavior\": {{\n",
    "                \"value\": \"Online behavior patterns\",\n",
    "                \"reasoning\": \"Based on activity patterns\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"activity_patterns\": {{\n",
    "                \"value\": \"When and how they use Reddit\",\n",
    "                \"reasoning\": \"Analysis of posting patterns\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"primary_motivations\": {{\n",
    "                \"value\": \"What drives them\",\n",
    "                \"reasoning\": \"Explanation\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"frustrations\": {{\n",
    "                \"value\": \"Common frustrations and pain points\",\n",
    "                \"reasoning\": \"Based on complaints and issues mentioned\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"goals\": {{\n",
    "                \"value\": \"Apparent goals and aspirations\",\n",
    "                \"reasoning\": \"Explanation\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"tech_savviness\": {{\n",
    "                \"value\": \"Technical skill level assessment\",\n",
    "                \"reasoning\": \"Based on technical discussions\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"preferred_platforms\": {{\n",
    "                \"value\": \"Preferred platforms and tools\",\n",
    "                \"reasoning\": \"Based on mentions and usage\",\n",
    "                \"evidence\": [\"Supporting quotes\"]\n",
    "            }},\n",
    "            \"representative_quote\": {{\n",
    "                \"value\": \"A quote that best represents their personality\",\n",
    "                \"reasoning\": \"Why this quote is representative\",\n",
    "                \"evidence\": [\"The actual quote from their content\"]\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        IMPORTANT: \n",
    "        - Use ONLY actual quotes from the user's posts and comments as evidence\n",
    "        - If information is not available or unclear, state \"Unknown\" for the value\n",
    "        - Be specific and cite real content, not generic statements\n",
    "        - Focus on what can be reasonably inferred from the available content\n",
    "        - Ensure all evidence quotes are actual text from the user's content\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(\"ğŸ¤– Analyzing with Gemini AI...\")\n",
    "            response = self.gemini_model.generate_content(prompt)\n",
    "            \n",
    "            # Clean up the response text to extract JSON\n",
    "            response_text = response.text.strip()\n",
    "            \n",
    "            # Remove markdown code blocks if present\n",
    "            if response_text.startswith('```json'):\n",
    "                response_text = response_text[7:]\n",
    "            if response_text.startswith('```'):\n",
    "                response_text = response_text[3:]\n",
    "            if response_text.endswith('```'):\n",
    "                response_text = response_text[:-3]\n",
    "            \n",
    "            # Parse JSON response\n",
    "            ai_analysis = json.loads(response_text)\n",
    "            print(\"âœ“ AI analysis completed\")\n",
    "            return ai_analysis\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"âŒ Error parsing AI response as JSON: {e}\")\n",
    "            print(\"Raw response:\", response.text[:500])\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error with Gemini analysis: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_citations(self, evidence_quotes: List[str], user_data: Dict) -> List[Citation]:\n",
    "        \"\"\"Create Citation objects from evidence quotes\"\"\"\n",
    "        citations = []\n",
    "        \n",
    "        for quote in evidence_quotes:\n",
    "            # Find the quote in posts or comments\n",
    "            citation = self._find_quote_source(quote, user_data)\n",
    "            if citation:\n",
    "                citations.append(citation)\n",
    "        \n",
    "        return citations\n",
    "    \n",
    "    def _find_quote_source(self, quote: str, user_data: Dict) -> Optional[Citation]:\n",
    "        \"\"\"Find the source of a quote in user data\"\"\"\n",
    "        # Clean the quote for matching\n",
    "        clean_quote = quote.strip().lower()\n",
    "        \n",
    "        # Search in posts\n",
    "        for post in user_data['posts']:\n",
    "            if clean_quote in post['content'].lower() or clean_quote in post['title'].lower():\n",
    "                return Citation(\n",
    "                    content=quote,\n",
    "                    post_type='post',\n",
    "                    url=post['url'],\n",
    "                    created_utc=post['created_utc'],\n",
    "                    subreddit=post['subreddit'],\n",
    "                    score=post['score']\n",
    "                )\n",
    "        \n",
    "        # Search in comments\n",
    "        for comment in user_data['comments']:\n",
    "            if clean_quote in comment['content'].lower():\n",
    "                return Citation(\n",
    "                    content=quote,\n",
    "                    post_type='comment',\n",
    "                    url=comment['url'],\n",
    "                    created_utc=comment['created_utc'],\n",
    "                    subreddit=comment['subreddit'],\n",
    "                    score=comment['score']\n",
    "                )\n",
    "        \n",
    "        # If not found, create a generic citation\n",
    "        return Citation(\n",
    "            content=quote,\n",
    "            post_type='unknown',\n",
    "            url='',\n",
    "            created_utc=0,\n",
    "            subreddit='unknown',\n",
    "            score=0\n",
    "        )\n",
    "    \n",
    "    def create_persona(self, user_data: Dict, ai_analysis: Dict) -> UserPersona:\n",
    "        \"\"\"Create a UserPersona object from analyzed data\"\"\"\n",
    "        \n",
    "        def create_characteristic(key: str) -> PersonaCharacteristic:\n",
    "            analysis = ai_analysis.get(key, {})\n",
    "            citations = self.create_citations(analysis.get('evidence', []), user_data)\n",
    "            return PersonaCharacteristic(\n",
    "                value=analysis.get('value', 'Unknown'),\n",
    "                citations=citations\n",
    "            )\n",
    "        \n",
    "        return UserPersona(\n",
    "            estimated_age=create_characteristic('estimated_age'),\n",
    "            occupation=create_characteristic('occupation'),\n",
    "            location=create_characteristic('location'),\n",
    "            relationship_status=create_characteristic('relationship_status'),\n",
    "            personality_type=create_characteristic('personality_type'),\n",
    "            interests=create_characteristic('interests'),\n",
    "            values=create_characteristic('values'),\n",
    "            communication_style=create_characteristic('communication_style'),\n",
    "            online_behavior=create_characteristic('online_behavior'),\n",
    "            activity_patterns=create_characteristic('activity_patterns'),\n",
    "            primary_motivations=create_characteristic('primary_motivations'),\n",
    "            frustrations=create_characteristic('frustrations'),\n",
    "            goals=create_characteristic('goals'),\n",
    "            tech_savviness=create_characteristic('tech_savviness'),\n",
    "            preferred_platforms=create_characteristic('preferred_platforms'),\n",
    "            representative_quote=create_characteristic('representative_quote'),\n",
    "            username=user_data['username'],\n",
    "            analysis_date=datetime.now().strftime('%Y-%m-%d'),\n",
    "            total_posts=len(user_data['posts']),\n",
    "            total_comments=len(user_data['comments']),\n",
    "            account_age_days=int(user_data['account_age_days']),\n",
    "            karma=user_data['total_karma']\n",
    "        )\n",
    "    \n",
    "    def format_persona_report(self, persona: UserPersona) -> str:\n",
    "        \"\"\"Format the persona into a readable report\"\"\"\n",
    "        \n",
    "        def format_characteristic(name: str, char: PersonaCharacteristic) -> str:\n",
    "            result = f\"\\n{name.upper().replace('_', ' ')}: {char.value}\\n\"\n",
    "            if char.citations:\n",
    "                result += \"Citations:\\n\"\n",
    "                for i, citation in enumerate(char.citations, 1):\n",
    "                    result += f\"  {i}. [{citation.post_type.upper()}] {citation.content[:100]}...\\n\"\n",
    "                    if citation.url:\n",
    "                        result += f\"     Source: {citation.url}\\n\"\n",
    "                    result += f\"     Subreddit: r/{citation.subreddit} | Score: {citation.score}\\n\\n\"\n",
    "            return result\n",
    "        \n",
    "        report = f\"\"\"\n",
    "================================================================================\n",
    "                        REDDIT USER PERSONA REPORT\n",
    "================================================================================\n",
    "\n",
    "USERNAME: u/{persona.username}\n",
    "ANALYSIS DATE: {persona.analysis_date}\n",
    "ACCOUNT AGE: {persona.account_age_days} days\n",
    "TOTAL POSTS: {persona.total_posts}\n",
    "TOTAL COMMENTS: {persona.total_comments}\n",
    "KARMA: {persona.karma}\n",
    "\n",
    "================================================================================\n",
    "                            PERSONA OVERVIEW\n",
    "================================================================================\n",
    "{format_characteristic('Representative Quote', persona.representative_quote)}\n",
    "\n",
    "================================================================================\n",
    "                            DEMOGRAPHICS\n",
    "================================================================================\n",
    "{format_characteristic('Estimated Age', persona.estimated_age)}\n",
    "{format_characteristic('Occupation', persona.occupation)}\n",
    "{format_characteristic('Location', persona.location)}\n",
    "{format_characteristic('Relationship Status', persona.relationship_status)}\n",
    "\n",
    "================================================================================\n",
    "                            PERSONALITY & VALUES\n",
    "================================================================================\n",
    "{format_characteristic('Personality Type', persona.personality_type)}\n",
    "{format_characteristic('Interests', persona.interests)}\n",
    "{format_characteristic('Values', persona.values)}\n",
    "\n",
    "================================================================================\n",
    "                            BEHAVIORAL PATTERNS\n",
    "================================================================================\n",
    "{format_characteristic('Communication Style', persona.communication_style)}\n",
    "{format_characteristic('Online Behavior', persona.online_behavior)}\n",
    "{format_characteristic('Activity Patterns', persona.activity_patterns)}\n",
    "\n",
    "================================================================================\n",
    "                            MOTIVATIONS & GOALS\n",
    "================================================================================\n",
    "{format_characteristic('Primary Motivations', persona.primary_motivations)}\n",
    "{format_characteristic('Frustrations', persona.frustrations)}\n",
    "{format_characteristic('Goals', persona.goals)}\n",
    "\n",
    "================================================================================\n",
    "                            TECHNICAL PROFILE\n",
    "================================================================================\n",
    "{format_characteristic('Tech Savviness', persona.tech_savviness)}\n",
    "{format_characteristic('Preferred Platforms', persona.preferred_platforms)}\n",
    "\n",
    "================================================================================\n",
    "                            END OF REPORT\n",
    "================================================================================\n",
    "\"\"\"\n",
    "        return report\n",
    "    \n",
    "    def save_persona_to_file(self, persona: UserPersona, filename: str = None):\n",
    "        \"\"\"Save persona report to a text file\"\"\"\n",
    "        if filename is None:\n",
    "            filename = f\"persona_{persona.username}_{persona.analysis_date}.txt\"\n",
    "        \n",
    "        report = self.format_persona_report(persona)\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"ğŸ’¾ Persona report saved to: {filename}\")\n",
    "    \n",
    "    def generate_persona_from_url(self, profile_url: str, limit: int = 100) -> UserPersona:\n",
    "        \"\"\"Main method to generate persona from Reddit profile URL\"\"\"\n",
    "        try:\n",
    "            # Extract username from URL\n",
    "            username = self.extract_username_from_url(profile_url)\n",
    "            print(f\"ğŸ‘¤ Analyzing user: u/{username}\")\n",
    "            \n",
    "            # Scrape user data\n",
    "            user_data = self.scrape_user_data(username, limit)\n",
    "            if not user_data:\n",
    "                raise Exception(\"Failed to scrape user data\")\n",
    "            \n",
    "            # Analyze with AI\n",
    "            ai_analysis = self.analyze_with_gemini(user_data)\n",
    "            if not ai_analysis:\n",
    "                raise Exception(\"Failed to analyze with AI\")\n",
    "            \n",
    "            # Create persona\n",
    "            persona = self.create_persona(user_data, ai_analysis)\n",
    "            \n",
    "            # Save to file\n",
    "            self.save_persona_to_file(persona)\n",
    "            \n",
    "            return persona\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error generating persona: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def setup_credentials():\n",
    "    \"\"\"Interactive setup for API credentials\"\"\"\n",
    "    print(\"ğŸ” Setting up API credentials\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Reddit credentials\n",
    "    print(\"\\n1. Reddit API Setup:\")\n",
    "    print(\"   - Go to https://www.reddit.com/prefs/apps\")\n",
    "    print(\"   - Create a new app (choose 'script' type)\")\n",
    "    print(\"   - Note your Client ID and Client Secret\")\n",
    "    \n",
    "    reddit_client_id = input(\"\\nEnter Reddit Client ID: \").strip()\n",
    "    reddit_client_secret = input(\"Enter Reddit Client Secret: \").strip()\n",
    "    reddit_user_agent = input(\"Enter Reddit User Agent (or press Enter for default): \").strip()\n",
    "    if not reddit_user_agent:\n",
    "        reddit_user_agent = \"PersonaGenerator/1.0\"\n",
    "    \n",
    "    # Gemini credentials\n",
    "    print(\"\\n2. Gemini API Setup:\")\n",
    "    print(\"   - Go to https://makersuite.google.com/app/apikey\")\n",
    "    print(\"   - Create a new API key\")\n",
    "    \n",
    "    gemini_api_key = input(\"\\nEnter Gemini API Key: \").strip()\n",
    "    \n",
    "    # Store in environment variables for current session\n",
    "    os.environ['REDDIT_CLIENT_ID'] = reddit_client_id\n",
    "    os.environ['REDDIT_CLIENT_SECRET'] = reddit_client_secret\n",
    "    os.environ['REDDIT_USER_AGENT'] = reddit_user_agent\n",
    "    os.environ['GEMINI_API_KEY'] = gemini_api_key\n",
    "    \n",
    "    print(\"\\nâœ… Credentials configured for current session!\")\n",
    "    return reddit_client_id, reddit_client_secret, reddit_user_agent, gemini_api_key\n",
    "\n",
    "def quick_setup(reddit_client_id: str, reddit_client_secret: str, gemini_api_key: str, \n",
    "                reddit_user_agent: str = \"PersonaGenerator/1.0\"):\n",
    "    \"\"\"Quick setup with provided credentials\"\"\"\n",
    "    os.environ['REDDIT_CLIENT_ID'] = reddit_client_id\n",
    "    os.environ['REDDIT_CLIENT_SECRET'] = reddit_client_secret\n",
    "    os.environ['REDDIT_USER_AGENT'] = reddit_user_agent\n",
    "    os.environ['GEMINI_API_KEY'] = gemini_api_key\n",
    "    print(\"âœ… Credentials configured!\")\n",
    "\n",
    "def generate_persona(profile_url: str, limit: int = 100):\n",
    "    \"\"\"Main function to generate persona - simplified for notebook use\"\"\"\n",
    "    try:\n",
    "        generator = RedditUserPersonaGenerator()\n",
    "        persona = generator.generate_persona_from_url(profile_url, limit)\n",
    "        \n",
    "        if persona:\n",
    "            print(f\"\\nğŸ‰ Persona generated successfully for u/{persona.username}!\")\n",
    "            print(f\"ğŸ“„ Report saved to: persona_{persona.username}_{persona.analysis_date}.txt\")\n",
    "            \n",
    "            # Display summary\n",
    "            print(f\"\\nğŸ“Š Summary:\")\n",
    "            print(f\"   Age: {persona.estimated_age.value}\")\n",
    "            print(f\"   Occupation: {persona.occupation.value}\")\n",
    "            print(f\"   Location: {persona.location.value}\")\n",
    "            print(f\"   Interests: {persona.interests.value}\")\n",
    "            print(f\"   Quote: {persona.representative_quote.value}\")\n",
    "            \n",
    "            return persona\n",
    "        else:\n",
    "            print(\"âŒ Failed to generate persona\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "006b93f5-2aa4-4b66-9e93-0515e80e5bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Setting up API credentials\n",
      "==================================================\n",
      "\n",
      "1. Reddit API Setup:\n",
      "   - Go to https://www.reddit.com/prefs/apps\n",
      "   - Create a new app (choose 'script' type)\n",
      "   - Note your Client ID and Client Secret\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Reddit Client ID:  XRj8ThHhoU-jh25SePzTxA\n",
      "Enter Reddit Client Secret:  \t9gagKouyVu2L5FuqRnFtacpjQGcKpA\n",
      "Enter Reddit User Agent (or press Enter for default):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Gemini API Setup:\n",
      "   - Go to https://makersuite.google.com/app/apikey\n",
      "   - Create a new API key\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter Gemini API Key:  AIzaSyCXBFs1eq5jdYqdDm__phxVFkK0qx6MNbQ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Credentials configured for current session!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('XRj8ThHhoU-jh25SePzTxA',\n",
       " '9gagKouyVu2L5FuqRnFtacpjQGcKpA',\n",
       " 'PersonaGenerator/1.0',\n",
       " 'AIzaSyCXBFs1eq5jdYqdDm__phxVFkK0qx6MNbQ')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   setup_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57837c8a-5933-47d6-bfe7-7ae8e4aa593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/2] Analyzing: https://www.reddit.com/user/kojied/\n",
      "ğŸ‘¤ Analyzing user: u/kojied\n",
      "ğŸ” Scraping posts for u/kojied...\n",
      "ğŸ’¬ Scraping comments for u/kojied...\n",
      "âœ“ Found 31 posts and 100 comments\n",
      "ğŸ¤– Analyzing with Gemini AI...\n",
      "âœ“ AI analysis completed\n",
      "ğŸ’¾ Persona report saved to: persona_kojied_2025-07-16.txt\n",
      "\n",
      "ğŸ‰ Persona generated successfully for u/kojied!\n",
      "ğŸ“„ Report saved to: persona_kojied_2025-07-16.txt\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "   Age: 28-35\n",
      "   Occupation: iOS Developer\n",
      "   Location: New York City\n",
      "   Interests: iOS development, visionOS, spatial computing, Apple Vision Pro,  ChatGPT, Civilization V,  New York City nightlife (formerly!),  NFTs (previously),  gaming (Manor Lords, One Piece),  Pokemon, Anime (Edgerunners).\n",
      "   Quote: Iâ€™ve been trying to actually use the Vision Pro to get some work done, but without github and visual studio code, itâ€™s not been the easiest (also obviously no terminal).\n",
      "âœ… Completed: u/kojied\n",
      "\n",
      "[2/2] Analyzing: https://www.reddit.com/user/Hungry-Move-6603/\n",
      "ğŸ‘¤ Analyzing user: u/Hungry-Move-6603\n",
      "ğŸ” Scraping posts for u/Hungry-Move-6603...\n",
      "ğŸ’¬ Scraping comments for u/Hungry-Move-6603...\n",
      "âœ“ Found 3 posts and 12 comments\n",
      "ğŸ¤– Analyzing with Gemini AI...\n",
      "âœ“ AI analysis completed\n",
      "ğŸ’¾ Persona report saved to: persona_Hungry-Move-6603_2025-07-16.txt\n",
      "\n",
      "ğŸ‰ Persona generated successfully for u/Hungry-Move-6603!\n",
      "ğŸ“„ Report saved to: persona_Hungry-Move-6603_2025-07-16.txt\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "   Age: 30-45\n",
      "   Occupation: Business Owner/Manager\n",
      "   Location: Lucknow, India\n",
      "   Interests: Finding productive weekend activities, reading (potentially), healthy and quick meals\n",
      "   Quote: COMMENT: Malls are a thing of past - and entire LKO is on steroids in rents cost, despite low to no demand.\n",
      "âœ… Completed: u/Hungry-Move-6603\n",
      "\n",
      "ğŸ Sample generation completed!\n"
     ]
    }
   ],
   "source": [
    "sample_users = [\n",
    "    \"https://www.reddit.com/user/kojied/\",\n",
    "    \"https://www.reddit.com/user/Hungry-Move-6603/\"\n",
    "]\n",
    "\n",
    "for i, user_url in enumerate(sample_users, 1):\n",
    "    print(f\"\\n[{i}/{len(sample_users)}] Analyzing: {user_url}\")\n",
    "    try:\n",
    "        persona = generate_persona(user_url)\n",
    "        if persona:\n",
    "            print(f\"âœ… Completed: u/{persona.username}\")\n",
    "        else:\n",
    "            print(f\"âŒ Failed: {user_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error with {user_url}: {e}\")\n",
    "\n",
    "print(\"\\nğŸ Sample generation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abcbbbe6-a244-4d34-9db4-585aed1c8b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a Reddit profile URL to analyze:  https://www.reddit.com/user/Hungry-Move-6603/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ Analyzing user: u/Hungry-Move-6603\n",
      "ğŸ” Scraping posts for u/Hungry-Move-6603...\n",
      "ğŸ’¬ Scraping comments for u/Hungry-Move-6603...\n",
      "âœ“ Found 3 posts and 12 comments\n",
      "ğŸ¤– Analyzing with Gemini AI...\n",
      "âœ“ AI analysis completed\n",
      "ğŸ’¾ Persona report saved to: persona_Hungry-Move-6603_2025-07-16.txt\n",
      "\n",
      "ğŸ‰ Persona generated successfully for u/Hungry-Move-6603!\n",
      "ğŸ“„ Report saved to: persona_Hungry-Move-6603_2025-07-16.txt\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "   Age: 30-45\n",
      "   Occupation: Business Owner\n",
      "   Location: Lucknow, India\n",
      "   Interests: Finding productive weekend activities, exploring cafes and reading clubs in Lucknow, and potentially healthy eating.\n",
      "   Quote: COMMENT: Malls are a thing of past - and entire LKO is on steroids in rents cost, despite low to no demand.\n",
      "âœ… Analysis complete for u/Hungry-Move-6603\n"
     ]
    }
   ],
   "source": [
    "custom_url = input(\"Enter a Reddit profile URL to analyze: \")\n",
    "if custom_url:\n",
    "    persona = generate_persona(custom_url)\n",
    "    if persona:\n",
    "        print(f\"âœ… Analysis complete for u/{persona.username}\")\n",
    "    else:\n",
    "        print(\"âŒ Analysis failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30475bca-50b3-497d-9246-c4157b545f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Generated persona files:\n",
      "  - persona_Hungry-Move-6603_2025-07-16.txt\n",
      "  - persona_kojied_2025-07-15.txt\n",
      "  - persona_kojied_2025-07-16.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "txt_files = [f for f in os.listdir('.') if f.startswith('persona_') and f.endswith('.txt')]\n",
    "print(\"ğŸ“ Generated persona files:\")\n",
    "for file in txt_files:\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2a882-33e7-481e-8ef5-f74d3b2ca4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
